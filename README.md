# üß† AI-Driven Brain-Computer Interface (BCI) with Graphene-Based Signal Amplification

Welcome to the official repository for my independent research project focused on building a non-invasive Brain-Computer Interface (BCI) system. This project explores how simulated **graphene-based neural signal amplification** and **adaptive deep learning models** can translate human thought into real-time digital actions.

**Author**: Pranav Rathod (19, India)  
**Status**: Active Research | Early Prototype  
**Affiliations**: Community-supported | Collaborating with insights from Stanford & CMU open research

---

## üöÄ Project Overview

This project simulates a next-gen BCI system by integrating:
- Graphene-inspired signal amplification
- Real EEG data from public datasets
- AI models for decoding mental intent into executable commands

The system is designed to aid individuals with **paralysis, speech disorders**, and **mobility impairments** by enabling direct communication from brain to machine‚Äîwithout surgical implants.

---

## üß™ Scientific Motivation

Inspired by research in **graphene electronics** and breakthroughs in **speech neuroprosthetics**, this project investigates:
- How graphene-like amplification might improve EEG signal fidelity
- How deep learning can decode inner speech or intent from neural signals
- Whether these can be combined into a fully non-invasive BCI pipeline

Reference support includes:
- [Stanford‚Äôs Speech BCI Dataset (Dryad)](https://doi.org/10.5061/dryad.x69p8czpq)
- [Nature 2023: High-Performance Speech Neuroprosthesis](https://www.nature.com/articles/s41586-023-06202-0)
- [Willett et al. RNN Decoder GitHub](https://github.com/fwillett/speechBCI)

---
## ‚öôÔ∏è System Architecture

```
[EEG Data Input (real/simulated)]
                |
                v
[Graphene Amplifier Simulation]
                |
                v
[Preprocessing & Noise Reduction]
                |
                v
[Deep Learning Model (CNN/RNN)]
                |
                v
[Thought Prediction / Intent Output]
                |
                v
[Applications: Cursor / Text / Prosthetics]
```

---
## üìÇ Repository Structure

```
‚îú‚îÄ‚îÄ Graphene_Amplifier1.ipynb         # Jupyter notebook for graphene amplifier simulation
‚îú‚îÄ‚îÄ BCI_AI_Summary_PranavRathod.pdf   # Visual and written proposal
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ .gitignore
```

---

## ‚¨áÔ∏è Installation & Running

### Option 1: Run on Google Colab

> Upload your EEG `.mat` or `.csv` file  
> Open `Graphene_Amplifier1.ipynb`  
> Visualize raw vs. amplified EEG signals

### Option 2: Local Setup

```bash
git clone https://github.com/PranavRathod399/BCI_graphene_prototype.git
cd BCI_graphene_prototype
# Install necessary packages as per the notebook requirements
```

---

## üß† Demo Output (to be updated)

---

## üìÖ Roadmap

- [x] Graphene-inspired amplifier (simulated)  
- [x] Dryad EEG dataset integration  
- [ ] CNN/RNN for intent decoding  
- [ ] Signal classification benchmarking  
- [ ] Graphene hardware exploration (future)  
- [ ] Full BCI prototype UI  

---

## ü§ù Contributions & Feedback

This is an independent, learning-driven project. I'm always open to:

- Feedback on architecture or models  
- Help with decoding models and preprocessing  
- Mentorship or collaboration  

> Email: pranavr399@gmail.com  
> GitHub: [github.com/PranavRathod399](https://github.com/PranavRathod399)

---

## ‚öñÔ∏è License

This project is licensed under the MIT License‚Äîopen to use, modification, and sharing for non-commercial and educational purposes.

---

**Developed independently by Pranav Rathod ‚Äî driven by a passion to build real-world solutions using thought-powered technology.**
